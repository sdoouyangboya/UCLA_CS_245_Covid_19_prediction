{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOnRlu8/NtNY6+ORcU6PELo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sripathm2/UCLA_CS_245_Project5/blob/GNN/GNN/MPNN%2BLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oTGuos50JVi"
      },
      "source": [
        "%pip install spektral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKKvny3fuAGM"
      },
      "source": [
        "import numpy as np\r\n",
        "from scipy import sparse\r\n",
        "import tensorflow as tf\r\n",
        "import spektral\r\n",
        "from spektral.layers.ops import sp_matrix_to_sp_tensor\r\n",
        "from spektral.datasets.mnist import MNIST\r\n",
        "\r\n",
        "data = MNIST()\r\n",
        "\r\n",
        "\r\n",
        "class Net(tf.keras.Model):\r\n",
        "    def __init__(self, window=6, dropout=.5, **kwargs):\r\n",
        "        \"\"\"\r\n",
        "        Window: int. Window of days\r\n",
        "        #LSTM hidden states: 64\r\n",
        "        Training: 500 epocs, batchsize 8, Adam optimizer, LR 10-3\r\n",
        "        \"\"\"\r\n",
        "        super().__init__(**kwargs)\r\n",
        "        self._nets = [self.build_MPNN_unit(dropout) for i in range(286)]\r\n",
        "        self.permute = tf.keras.layers.Permute((2,1,3))\r\n",
        "        self.flatten = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())\r\n",
        "        self.LSTM1 = tf.keras.layers.LSTM(52, return_sequences=True)\r\n",
        "        self.LSTM2 = tf.keras.layers.LSTM(52, return_sequences=False,\r\n",
        "                                          return_state=True)\r\n",
        "\r\n",
        "    def build_MPNN_unit(self, dropout):\r\n",
        "        L1 = []\r\n",
        "        L1.append(\r\n",
        "            spektral.layers.MessagePassing(aggregate='sum',\r\n",
        "                                           activation='relu')\r\n",
        "            )\r\n",
        "        L1.append(\r\n",
        "            tf.keras.layers.BatchNormalization()\r\n",
        "            )\r\n",
        "        L1.append(\r\n",
        "            tf.keras.layers.Dropout(dropout)\r\n",
        "            )\r\n",
        "        L2 = []\r\n",
        "        L2.append(\r\n",
        "            spektral.layers.MessagePassing(aggregate='sum',\r\n",
        "                                           activation='relu')\r\n",
        "            )\r\n",
        "        L2.append(\r\n",
        "            tf.keras.layers.BatchNormalization()\r\n",
        "            )\r\n",
        "        L2.append(\r\n",
        "            tf.keras.layers.Dropout(dropout)\r\n",
        "            )\r\n",
        "        return (L1,L2)\r\n",
        "\r\n",
        "\r\n",
        "    def run_MPNN_unit(self, Adj, X, net_id):\r\n",
        "        L1, L2 = self._nets[net_id]\r\n",
        "        y = None\r\n",
        "        for i in range(0,len(L1)):\r\n",
        "            if i == 0: # MessagePassing layer\r\n",
        "                y = L1[i].propagate(X, Adj)\r\n",
        "                continue\r\n",
        "            # print(i,L1[i])#, y)\r\n",
        "            y = L1[i](y)\r\n",
        "        H1 = y\r\n",
        "        for i in range(0, len(L2)):\r\n",
        "            if i == 0: # MessagePassing Layer\r\n",
        "                y = L2[i].propagate(y, Adj)\r\n",
        "                continue\r\n",
        "            y = L2[i](y)\r\n",
        "        H2 = y\r\n",
        "        return tf.concat((H1,H2), axis=1)\r\n",
        "    \r\n",
        "    def call(self, input):\r\n",
        "        X, Adj = input\r\n",
        "        H_list = []\r\n",
        "        X = X[0]\r\n",
        "        Adj = Adj[0]\r\n",
        "        for i in range(Adj.shape[0]):\r\n",
        "          a = sp_matrix_to_sp_tensor(Adj[i])\r\n",
        "          H = self.run_MPNN_unit(a, X[i], i)\r\n",
        "          H_list.append(H)\r\n",
        "        H_out = tf.expand_dims(H_list, axis=0)\r\n",
        "        print('H_out: ', H_out.shape)\r\n",
        "        #LSTM_input = self.permute(H_out)[0]\r\n",
        "        LSTM_input = self.flatten(H_out)\r\n",
        "        print('LSTM Input: ',LSTM_input.shape)\r\n",
        "        x = self.LSTM1(inputs=LSTM_input)\r\n",
        "        print('After First LSTM: ',x.shape)\r\n",
        "        x, final_memory_state, final_carry_state = self.LSTM2(inputs=x)\r\n",
        "        print('After Second LSTM: ',x.shape)\r\n",
        "        print('Feature matrix: ', X.shape)\r\n",
        "        x = tf.transpose(x)\r\n",
        "        print('Output of LSTM: ',x)\r\n",
        "        #x = X+x\r\n",
        "        #Lin?\r\n",
        "        #x = tf.keras.activations.relu(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "# Create random Adj Matrices\r\n",
        "A_list = []\r\n",
        "for i in range(286):\r\n",
        "  temp = np.zeros([52,52])\r\n",
        "  for j in range(np.random.randint(1,25)):\r\n",
        "    r = np.random.randint(0,52)\r\n",
        "    s = np.random.randint(0,52)\r\n",
        "    n = np.random.randn()\r\n",
        "    temp[r,s] = n\r\n",
        "    temp[s,r] = n\r\n",
        "  A_list.append(temp)\r\n",
        "Adj = tf.expand_dims(A_list, axis=0)[0]\r\n",
        "\r\n",
        "# Create random node feature matrices\r\n",
        "X = [np.random.rand(52, 5) for i in range(0,286)]\r\n",
        "X = tf.expand_dims(X, axis=0)[0]\r\n",
        "\r\n",
        "# Create random labels\r\n",
        "y = np.random.rand(52, 1)\r\n",
        "\r\n",
        "X2 = tf.expand_dims(X, 0)\r\n",
        "Adj2 = tf.expand_dims(Adj,0)\r\n",
        "y2 = tf.expand_dims(y,0)\r\n",
        "input = (X2, Adj2)\r\n",
        "model = Net(window=6)\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=tf.keras.losses.MeanSquaredError(), metrics= ['mse'])\r\n",
        "# model.fit(x=Adj2, y=y2, epochs=5)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCgo-E4OkTh2",
        "outputId": "a4f94aee-e88d-4e9a-fabd-31591d09b84c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras.layers import Input, Dropout\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.regularizers import l2\r\n",
        "\r\n",
        "from spektral.data.loaders import SingleLoader\r\n",
        "from spektral.datasets.citation import Citation\r\n",
        "from spektral.layers import GCNConv\r\n",
        "from spektral.transforms import LayerPreprocess, AdjToSpTensor\r\n",
        "\r\n",
        "# Load data\r\n",
        "dataset = Citation('cora',\r\n",
        "                   transforms=[LayerPreprocess(GCNConv), AdjToSpTensor()])\r\n",
        "mask_tr, mask_va, mask_te = dataset.mask_tr, dataset.mask_va, dataset.mask_te\r\n",
        "\r\n",
        "# Parameters\r\n",
        "channels = 16          # Number of channels in the first layer\r\n",
        "dropout = 0.5          # Dropout rate for the features\r\n",
        "l2_reg = 5e-4 / 2      # L2 regularization rate\r\n",
        "learning_rate = 1e-2   # Learning rate\r\n",
        "epochs = 200           # Number of training epochs\r\n",
        "patience = 10          # Patience for early stopping\r\n",
        "a_dtype = dataset[0].a.dtype  # Only needed for TF 2.1\r\n",
        "\r\n",
        "N = dataset.n_nodes          # Number of nodes in the graph\r\n",
        "F = dataset.n_node_features  # Original size of node features\r\n",
        "n_out = dataset.n_labels     # Number of classes\r\n",
        "\r\n",
        "# Model definition\r\n",
        "x_in = Input(shape=(F,))\r\n",
        "a_in = Input((N,), sparse=True, dtype=a_dtype)\r\n",
        "\r\n",
        "do_1 = Dropout(dropout)(x_in)\r\n",
        "gc_1 = GCNConv(channels,\r\n",
        "               activation='relu',\r\n",
        "               kernel_regularizer=l2(l2_reg),\r\n",
        "               use_bias=False)([do_1, a_in])\r\n",
        "do_2 = Dropout(dropout)(gc_1)\r\n",
        "gc_2 = GCNConv(n_out,\r\n",
        "               activation='softmax',\r\n",
        "               use_bias=False)([do_2, a_in])\r\n",
        "\r\n",
        "# Build model\r\n",
        "model = Model(inputs=[x_in, a_in], outputs=gc_2)\r\n",
        "optimizer = Adam(lr=learning_rate)\r\n",
        "model.compile(optimizer=optimizer,\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              weighted_metrics=['acc'])\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# Train model\r\n",
        "loader_tr = SingleLoader(dataset, sample_weights=mask_tr)\r\n",
        "loader_va = SingleLoader(dataset, sample_weights=mask_va)\r\n",
        "model.fit(loader_tr.load(),\r\n",
        "          steps_per_epoch=loader_tr.steps_per_epoch,\r\n",
        "          epochs=1)\r\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer gcn_conv_6 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "WARNING:tensorflow:Layer gcn_conv_7 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/sparse/_index.py:126: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_7 (InputLayer)            [(None, 1433)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2312 (Dropout)          (None, 1433)         0           input_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_8 (InputLayer)            [(None, 2708)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gcn_conv_6 (GCNConv)            (None, 16)           22928       dropout_2312[0][0]               \n",
            "                                                                 input_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2313 (Dropout)          (None, 16)           0           gcn_conv_6[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "gcn_conv_7 (GCNConv)            (None, 7)            112         dropout_2313[0][0]               \n",
            "                                                                 input_8[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,040\n",
            "Trainable params: 23,040\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.1084 - acc: 0.1286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f90833c5160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhxxOCe8npGX",
        "outputId": "ed4b3e68-4469-420a-95e0-c1c57b7cbb97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<RepeatDataset shapes: (((2708, 1433), (2708, 2708)), (2708, 7), (2708,)), types: ((tf.float32, tf.float64), tf.int32, tf.bool)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOjXYb87nwUF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}