{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP0gwkSC7ITw6crAqgjZuFo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sripathm2/UCLA_CS_245_Project5/blob/GNN/GNN/GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBrWtnTZD8CF",
        "outputId": "fffabaf6-c5c1-47bb-c027-c979085ad336"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZPc4X6x6xdA"
      },
      "source": [
        "#!pip install spektral\n",
        "import spektral\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Input, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "import tensorflow\n",
        "from spektral.data.loaders import SingleLoader\n",
        "from spektral.layers import GCNConv\n",
        "import spektral.transforms"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5S3OMQ4EKsE",
        "outputId": "5a982f97-b23e-4738-970f-a655dc094005"
      },
      "source": [
        "% cd /content/drive/MyDrive/CS245/UCLA_CS_245_Project5-GNN/GNN\n",
        "import build_data\n",
        "Adj, X, y = build_data.build_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/CS245/UCLA_CS_245_Project5-GNN/GNN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogdC9TBbFn6N",
        "outputId": "dee261b3-cd68-4cf5-aa32-def5d47c1485"
      },
      "source": [
        "print(Adj.shape)\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(286, 52, 52)\n",
            "(286, 52, 5)\n",
            "(286, 52, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJ6e67i2Fjid",
        "outputId": "e7ea27a7-339b-4806-8dc2-eb93eff790c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "dataset = [spektral.data.Graph(x=np.random.randint(0,1,size=(52,5)), a=sp.csr_matrix((52,52)))] # Placeholder data\n",
        "\n",
        "'''\n",
        "The input can only be an adjacency matrix of shape node x node. Node features has the same issue.\n",
        "'''\n",
        "'''\n",
        "x: np.array, the node features (shape (n_nodes, n_node_features));\n",
        "a: np.array or scipy.sparse matrix, the adjacency matrix (shape (n_nodes, n_nodes));\n",
        "e: np.array, the edge features (shape (n_nodes, n_nodes, n_edge_features) or (n_edges, n_edge_features));\n",
        "'''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nx: np.array, the node features (shape (n_nodes, n_node_features));\\na: np.array or scipy.sparse matrix, the adjacency matrix (shape (n_nodes, n_nodes));\\ne: np.array, the edge features (shape (n_nodes, n_nodes, n_edge_features) or (n_edges, n_edge_features));\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZOjcWGAHTAO"
      },
      "source": [
        "# Parameters\n",
        "channels = 16          # Number of channels in the first layer\n",
        "dropout = 0.5          # Dropout rate for the features\n",
        "l2_reg = 5e-4 / 2      # L2 regularization rate\n",
        "learning_rate = 1e-2   # Learning rate\n",
        "epochs = 200           # Number of training epochs\n",
        "patience = 10          # Patience for early stopping\n",
        "a_dtype = dataset[0].a.dtype  # Only needed for TF 2.1\n",
        "\n",
        "N = 51          # Number of nodes in the graph\n",
        "F = 5           # Original size of node features\n",
        "y = 5           # Label\n",
        "\n",
        "# GNN Class Definition\n",
        "class GNN(Model):\n",
        "  def __init__(self):\n",
        "    super(GNN,self).__init__()\n",
        "    # self.x_in = Input(shape=(F,))\n",
        "    # self.a_in = Input((N,), sparse=True, dtype=a_dtype)\n",
        "    self.do_1 = Dropout(dropout)\n",
        "    self.gc_1 = GCNConv(channels=channels,\n",
        "                   activation='relu',\n",
        "                   kernel_regularizer=l2(l2_reg),\n",
        "                   use_bias=False\n",
        "                  )\n",
        "    self.do_2 = Dropout(dropout)\n",
        "    self.gc_2 = GCNConv(channels=F,\n",
        "                       activation='softmax',\n",
        "                       use_bias=False\n",
        "                       )\n",
        "  def call(self, inputs):\n",
        "      # x_in = self.x_in(inputs)\n",
        "      # a_in = self.a_in(inputs)\n",
        "      print(inputs)\n",
        "      x_in = inputs[0]\n",
        "      a_in = inputs[1]\n",
        "      x = self.do_1(x_in)\n",
        "      x = self.gc_1([x, a_in])\n",
        "      x = self.do_2(x)\n",
        "      return self.gc_2([x, a_in])\n",
        "\n",
        "\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SHjAWo7TlgZ"
      },
      "source": [
        "print(X[0].shape)\r\n",
        "dataset = [spektral.data.Graph(x=X[0])]\r\n",
        "print(dataset[0])\r\n",
        "'''(<tf.Tensor 'Cast:0' shape=(68, 3) dtype=float32>, <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x7fa295c37080>)'''\r\n",
        "gnn = GNN()\r\n",
        "gnn.compile(optimizer=Adam(learning_rate=learning_rate), loss=tensorflow.keras.losses.MeanSquaredError(), metrics=['mse'])\r\n",
        "loader = SingleLoader(dataset)\r\n",
        "gnn.fit(loader.load(), steps_per_epoch=loader.steps_per_epoch, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27IfY5fIuYAN"
      },
      "source": [
        "# Parameters\n",
        "channels = 16          # Number of channels in the first layer\n",
        "dropout = 0.5          # Dropout rate for the features\n",
        "l2_reg = 5e-4 / 2      # L2 regularization rate\n",
        "learning_rate = 1e-2   # Learning rate\n",
        "epochs = 200           # Number of training epochs\n",
        "patience = 10          # Patience for early stopping\n",
        "a_dtype = dataset[0].a.dtype  # Only needed for TF 2.1\n",
        "\n",
        "N = 51          # Number of nodes in the graph\n",
        "F = 5           # Original size of node features\n",
        "y = 5           # Label\n",
        "\n",
        "\n",
        "# Model definition\n",
        "x_in = Input(shape=(F,))\n",
        "a_in = Input((N,), sparse=True, dtype=a_dtype)\n",
        "\n",
        "do_1 = Dropout(dropout)(x_in)\n",
        "gc_1 = GCNConv(channels,\n",
        "               activation='relu',\n",
        "               kernel_regularizer=l2(l2_reg),\n",
        "               use_bias=False)([do_1, a_in])\n",
        "do_2 = Dropout(dropout)(gc_1)\n",
        "gc_2 = GCNConv(y,\n",
        "               activation='softmax',\n",
        "               use_bias=False)([do_2, a_in])\n",
        "\n",
        "# Build model\n",
        "model = Model(inputs=[x_in, a_in], outputs=gc_2)\n",
        "optimizer = Adam(lr=learning_rate)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              weighted_metrics=['acc'])\n",
        "model.summary()\n",
        "\n",
        "# Train model\n",
        "loader = SingleLoader(dataset)\n",
        "model.fit(loader.load(),\n",
        "          steps_per_epoch=loader.steps_per_epoch,\n",
        "          epochs=epochs,\n",
        "          callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mbUOYW2TiDK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UbKvctbJnY2"
      },
      "source": [
        "\"\"\"\r\n",
        "This example implements the experiments on citation networks from the paper:\r\n",
        "Semi-Supervised Classification with Graph Convolutional Networks (https://arxiv.org/abs/1609.02907)\r\n",
        "Thomas N. Kipf, Max Welling\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras.layers import Input, Dropout\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.regularizers import l2\r\n",
        "\r\n",
        "from spektral.data.loaders import SingleLoader\r\n",
        "from spektral.datasets.citation import Citation\r\n",
        "from spektral.layers import GCNConv\r\n",
        "from spektral.transforms import LayerPreprocess, AdjToSpTensor\r\n",
        "\r\n",
        "# Load data\r\n",
        "dataset = Citation('cora',\r\n",
        "                   transforms=[LayerPreprocess(GCNConv), AdjToSpT\r\n",
        "                   \r\n",
        "                   \r\n",
        "                   \r\n",
        "                   \r\n",
        "                   \r\n",
        "                   nsor()])\r\n",
        "mask_tr, mask_va, mask_te = dataset.mask_tr, dataset.mask_va, dat\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "set.mask_te\r\n",
        "\r\n",
        "# Parameters\r\n",
        "channels = 16          # Number of channels in the first layer\r\n",
        "dropout = 0.5          # Dropout rate for the features\r\n",
        "l2_reg = 5e-4 / 2      # L2 regularization rate\r\n",
        "learning_rate = 1e-2   # Learning rate\r\n",
        "epochs = 200           # Number of training epochs\r\n",
        "patience = 10          # Patience for early stopping\r\n",
        "a_dtype = dataset[0].a.dtype  # Only needed for TF 2.1\r\n",
        "\r\n",
        "N = dataset.n_nodes          # Number of nodes in the graph\r\n",
        "F = dataset.n_node_features  # Original size of node features\r\n",
        "n_out = dataset.n_labels     # Number of classes\r\n",
        "\r\n",
        "# Model definition\r\n",
        "x_in = Input(shape=(F,))\r\n",
        "a_in = Input((N,), sparse=True, dtype=a_dtype)\r\n",
        "\r\n",
        "do_1 = Dropout(dropout)(x_in)\r\n",
        "gc_1 = GCNConv(channels,\r\n",
        "               activation='relu',\r\n",
        "               kernel_regularizer=l2(l2_reg),\r\n",
        "               use_bias=False)([do_1, a_in])\r\n",
        "do_2 = Dropout(dropout)(gc_1)\r\n",
        "gc_2 = GCNConv(n_out,\r\n",
        "               activation='softmax',\r\n",
        "               use_bias=False)([do_2, a_in])\r\n",
        "\r\n",
        "# Build model\r\n",
        "model = Model(inputs=[x_in, a_in], outputs=gc_2)\r\n",
        "optimizer = Adam(lr=learning_rate)\r\n",
        "model.compile(optimizer=optimizer,\r\n",
        "              loss='categorical_crossentropy',\r\n",
        "              weighted_metrics=['acc'])\r\n",
        "model.summary()\r\n",
        "\r\n",
        "# Train model\r\n",
        "loader_tr = SingleLoader(dataset, sample_weights=mask_tr)\r\n",
        "loader_va = SingleLoader(dataset, sample_weights=mask_va)\r\n",
        "model.fit(loader_tr.load(),\r\n",
        "          steps_per_epoch=loader_tr.steps_per_epoch,\r\n",
        "          validation_data=loader_va.load(),\r\n",
        "          validation_steps=loader_va.steps_per_epoch,\r\n",
        "          epochs=epochs,\r\n",
        "          callbacks=[EarlyStopping(patience=patience, restore_best_weights=True)])\r\n",
        "\r\n",
        "# Evaluate model\r\n",
        "print('Evaluating model.')\r\n",
        "loader_te = SingleLoader(dataset, sample_weights=mask_te)\r\n",
        "eval_results = model.evaluate(loader_te.load(), steps=loader_te.steps_per_epoch)\r\n",
        "print('Done.\\n'\r\n",
        "      'Test loss: {}\\n'\r\n",
        "      'Test accuracy: {}'.format(*eval_results))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}