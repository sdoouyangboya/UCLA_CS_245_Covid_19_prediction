{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOVVvStg7DPqOT/T84i8Be7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sripathm2/UCLA_CS_245_Project5/blob/GNN/GNN/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oTGuos50JVi"
      },
      "source": [
        "%pip install spektral"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKKvny3fuAGM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "outputId": "808957e2-c052-4ffc-bc18-8b384c3c92bb"
      },
      "source": [
        "import numpy as np\r\n",
        "from scipy import sparse\r\n",
        "import tensorflow as tf\r\n",
        "import spektral\r\n",
        "from spektral.layers.ops import sp_matrix_to_sp_tensor\r\n",
        "from spektral.datasets.mnist import MNIST\r\n",
        "\r\n",
        "data = MNIST()\r\n",
        "\r\n",
        "\r\n",
        "class Net(tf.keras.Model):\r\n",
        "    def __init__(self, window=6, dropout=.5, **kwargs):\r\n",
        "        \"\"\"\r\n",
        "        Window: int. Window of days\r\n",
        "        #LSTM hidden states: 64\r\n",
        "        Training: 500 epocs, batchsize 8, Adam optimizer, LR 10-3\r\n",
        "        \"\"\"\r\n",
        "        super().__init__(**kwargs)\r\n",
        "        self._nets = self.build_MPNN_unit(dropout)\r\n",
        "        self.permute = tf.keras.layers.Permute((2,1))\r\n",
        "        self.flatten = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())\r\n",
        "        self.LSTM1 = tf.keras.layers.LSTM(52, return_sequences=True)\r\n",
        "        self.LSTM2 = tf.keras.layers.LSTM(52, return_sequences=False,\r\n",
        "                                          return_state=True)\r\n",
        "\r\n",
        "    def build_MPNN_unit(self, dropout):\r\n",
        "        L1 = []\r\n",
        "        L1.append(\r\n",
        "            spektral.layers.MessagePassing(aggregate='sum',\r\n",
        "                                           activation='relu')\r\n",
        "            )\r\n",
        "        L1.append(\r\n",
        "            tf.keras.layers.BatchNormalization()\r\n",
        "            )\r\n",
        "        L1.append(\r\n",
        "            tf.keras.layers.Dropout(dropout)\r\n",
        "            )\r\n",
        "        L2 = []\r\n",
        "        L2.append(\r\n",
        "            spektral.layers.MessagePassing(aggregate='sum',\r\n",
        "                                           activation='relu')\r\n",
        "            )\r\n",
        "        L2.append(\r\n",
        "            tf.keras.layers.BatchNormalization()\r\n",
        "            )\r\n",
        "        L2.append(\r\n",
        "            tf.keras.layers.Dropout(dropout)\r\n",
        "            )\r\n",
        "        return (L1,L2)\r\n",
        "\r\n",
        "\r\n",
        "    def run_MPNN_unit(self, Adj, X):\r\n",
        "        L1, L2 = self._nets\r\n",
        "        y = None\r\n",
        "        for i in range(0,len(L1)):\r\n",
        "            if i == 0: # MessagePassing layer\r\n",
        "                y = L1[i].propagate(X, Adj)\r\n",
        "                continue\r\n",
        "            # print(i,L1[i])#, y)\r\n",
        "            y = L1[i](y)\r\n",
        "        H1 = y\r\n",
        "        for i in range(0, len(L2)):\r\n",
        "            if i == 0: # MessagePassing Layer\r\n",
        "                y = L2[i].propagate(y, Adj)\r\n",
        "                continue\r\n",
        "            y = L2[i](y)\r\n",
        "        H2 = y\r\n",
        "        return tf.concat((H1,H2), axis=1)\r\n",
        "    \r\n",
        "    def call(self, inputs):\r\n",
        "        Adj, X = inputs\r\n",
        "        H_list = []\r\n",
        "        for i in range(Adj.shape[0]):\r\n",
        "          a = sp_matrix_to_sp_tensor(Adj[i])\r\n",
        "          H = self.run_MPNN_unit(a, X[i])\r\n",
        "          H_list.append(H)\r\n",
        "        H_out = tf.expand_dims(H_list, axis=0)\r\n",
        "        #LSTM_input = self.permute(H_out)[0]\r\n",
        "        LSTM_input = self.flatten(H_out)\r\n",
        "        x = self.LSTM1(inputs=LSTM_input)\r\n",
        "        x, final_memory_state, final_carry_state = self.LSTM2(inputs=x)\r\n",
        "        x = tf.transpose(x)\r\n",
        "        print('Output shape of LSTM: ',x.shape)\r\n",
        "        print('Output of LSTM: ', x)\r\n",
        "        #x = X+x\r\n",
        "        #Lin?\r\n",
        "        #x = tf.keras.activations.relu(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "# Create random Adj Matrices\r\n",
        "A_list = []\r\n",
        "for i in range(286):\r\n",
        "  temp = np.zeros([52,52])\r\n",
        "  for j in range(np.random.randint(1,25)):\r\n",
        "    r = np.random.randint(0,52)\r\n",
        "    s = np.random.randint(0,52)\r\n",
        "    n = np.random.randn()\r\n",
        "    temp[r,s] = n\r\n",
        "    temp[s,r] = n\r\n",
        "  A_list.append(temp)\r\n",
        "Adj = tf.expand_dims(A_list, axis=0)[0]\r\n",
        "\r\n",
        "# Create random node feature matrices\r\n",
        "X = [np.random.rand(52, 5) for i in range(0,286)]\r\n",
        "X = tf.expand_dims(X, axis=0)[0]\r\n",
        "\r\n",
        "input = [Adj, X]\r\n",
        "# Create random labels\r\n",
        "y = np.random.rand(52, 1)\r\n",
        "\r\n",
        "model = Net(window=6)\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(),metrics='mse', loss=tf.keras.metrics.MeanSquaredError())\r\n",
        "model.fit(x=input, y=y, epochs=5)\r\n",
        "print('end')"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-163-03206e813e9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'end'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1061\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1115\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m             label, \", \".join(str(i.shape[0]) for i in nest.flatten(data)))\n\u001b[1;32m    281\u001b[0m       \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Please provide data which shares the same first dimension.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 286, 286\n  y sizes: 52\nPlease provide data which shares the same first dimension."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlzyt3qbse9r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}